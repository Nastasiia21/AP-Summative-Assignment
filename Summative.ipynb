{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa36e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter.font as tkFont\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List,Dict,Literal,Union,Any\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn  as sns\n",
    "import tkinter as tk\n",
    "import tkinter\n",
    "from tkinter import messagebox\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c497988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default plot style and adjust Seaborn's font scale\n",
    "plt.style.use('default')\n",
    "sns.set_theme(font_scale=0.7)\n",
    "\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        # Return a formatted string with both values and percentages\n",
    "        return '({v:d})'.format(v=val)\n",
    "    return my_autopct\n",
    "\n",
    "\"\"\"\n",
    "    Validate a date string in the format 'YYYY_MM_DD'.\n",
    "    \n",
    "    Args:\n",
    "        date_text (str): The date string to be validated.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the date format is incorrect.\n",
    "    \"\"\"\n",
    "def validate(date_text):\n",
    "    \n",
    "        try:\n",
    "            datetime.datetime.strptime(date_text, '%Y_%m_%d')\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Incorrect data format, should be YYYY_MM_DD\")\n",
    "        \n",
    "# translated format's operations\n",
    "def transform_df2json(df:pd.DataFrame) -> Dict:\n",
    "    # translate df to json\n",
    "    \"\"\"\n",
    "    Transforms a DataFrame into a JSON-like dictionary.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame to be transformed.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary where keys are column names and values are lists of column values.\n",
    "    \"\"\"\n",
    "    json_tmp = {}\n",
    "    for key in df.keys():\n",
    "        json_tmp[key] = df[key].values.tolist()\n",
    "    return json_tmp\n",
    "\n",
    "def transform_json2df(json_tmp:Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transforms a JSON-like dictionary back into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        json_tmp (Dict): The input JSON-like dictionary.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The reconstructed DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.array([json_tmp[key] for key in json_tmp]).T,columns=list(json_tmp.keys())).replace('nan',np.nan)\n",
    "    return df\n",
    "\n",
    "# Reading data\n",
    "def _load_dataset(folder_path:str) -> List[pd.DataFrame]:\n",
    "    assert os.path.isdir(folder_path)\n",
    "    path = Path(folder_path)\n",
    "    csv_paths = list(path.glob('*.csv'))\n",
    "    assert len(csv_paths) == 2\n",
    "    result = [pd.read_csv(f,encoding='ISO-8859-1') for f in csv_paths]\n",
    "    return [df.rename(columns={c:c.strip() for c in df.columns}) for df in result]\n",
    "\n",
    "def identify_csv(dfs:List[pd.DataFrame],feature_dict:Dict[str,str] = {'Antenna':'NGR','Param':'EID'}) -> Dict[str,pd.DataFrame]:\n",
    "    \"\"\"identify csv\n",
    "\n",
    "    Args:\n",
    "        dfs (List[pd.DataFrame]): data csvs\n",
    "        feature_dict (Dict[str,str]): Indicate the characteristics of the CSV file. example only key 'NGR' in Antenna\n",
    "                                    and only key 'EID' in Param -> {'Antenna':'NGR','Param':'EID'}\n",
    "    Returns:\n",
    "        Dict[str,pd.DataFrame]: {'Antenna file':DataFrame, 'Param file':DataFrame}\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    result['Antenna'] = dfs[0] if feature_dict['Antenna'] in dfs[0] else dfs[1]\n",
    "    result['Param'] = dfs[0] if feature_dict['Param'] in dfs[0] else dfs[1]\n",
    "    return result\n",
    "\n",
    "def load_dataset(folder_path:str,feature_dict:Dict[str,str] = {'Antenna':'NGR','Param':'EID'}) -> Dict[str,pd.DataFrame]:\n",
    "    \"\"\"load initial dataset from a folder path\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): the path of dataset folder\n",
    "        feature_dict (Dict[str,str]): Indicate the characteristics of the CSV file. example only key 'NGR' in Antenna\n",
    "                                    and only key 'EID' in Param -> {'Antenna':'NGR','Param':'EID'}\n",
    "\n",
    "    Returns:\n",
    "        Dict[pd.DataFrame]: {'Antenna':DataFrame, 'Param':DataFrame}\n",
    "    \"\"\"\n",
    "    df_list = _load_dataset(folder_path)\n",
    "    df_dict = identify_csv(df_list,feature_dict)\n",
    "    return df_dict\n",
    "\n",
    "# Data preprocessing\n",
    "# Dictionary of functions to process NaN values in DataFrames\n",
    "processing_nan_funcs = {'any': lambda df:df.dropna(axis=0,how='any'),\n",
    "                        'mean': lambda df:fill_df(df,'mean'),\n",
    "                        'std': lambda df:fill_df(df,'std'),\n",
    "                        'median': lambda df:fill_df(df,'median'),\n",
    "                        'mode': lambda df:fill_df(df,'mode')\n",
    "                        }\n",
    "\n",
    "#Fill NaN values in a DataFrame using the specified method.\n",
    "def fill_df(df:pd.DataFrame, method:Literal['mean','std','median','mode']='mean'):\n",
    "    \n",
    "    for c in df.columns:\n",
    "        if df[c].dtype.name == 'object':\n",
    "            df[c] = df[c].fillna(method='pad')\n",
    "            continue\n",
    "        if method == 'mean':\n",
    "            df[c] = df[c].fillna(df[c].mean())\n",
    "        elif method == 'std':\n",
    "            df[c] = df[c].fillna(df[c].std())\n",
    "        elif method == 'median':\n",
    "            df[c] = df[c].fillna(df[c].median())\n",
    "        elif method == 'mode':\n",
    "            df[c] = df[c].fillna(df[c].mode()[0])\n",
    "    return df\n",
    "\n",
    "def remove_data(df:pd.DataFrame,key:str = 'NGR',values:List[str]=['NZ02553847', 'SE213515', 'NT05399374', 'NT252675908'])->pd.DataFrame:\n",
    "    \"\"\"remove some data row from Antenna file\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Antenna Dataframe\n",
    "        key (str): key of dataframe, and remove row which key in valuesk\n",
    "        values (List[str]): values want to remove\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: clean df\n",
    "    \"\"\"\n",
    "    df  = df.drop(df[df[key].isin(values)].index)\n",
    "    return df\n",
    "\n",
    "def extract_infomation(df_dict:Dict[str,pd.DataFrame],EIDs:List[str]=['C18A', 'C18F', 'C188']) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        df_dict (Dict[str,pd.DataFrame]): {'Antenna':DataFrame, 'Param':DataFrame}\n",
    "        EIDs (List[str]): EIDs which want to extract\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: prepare dataframe\n",
    "    \"\"\"\n",
    "    prepare_df = df_dict['Param'].loc[df_dict['Param']['EID'].isin(EIDs)]\n",
    "    extract_idxs = prepare_df['id'].values.tolist()\n",
    "    prepare_left = df_dict['Antenna'].loc[df_dict['Antenna']['id'].isin(extract_idxs)]\n",
    "    prepare_left = prepare_left[['id','Site Height','In-Use Ae Ht','In-Use ERP Total']]\n",
    "    prepare_df = prepare_df.merge(prepare_left,on=['id'],how='left')\n",
    "    prepare_df = prepare_df.rename(columns={'In-Use Ae Ht':'Aerial height(m)',\n",
    "                       'In-Use ERP Total':'Power(kW)'})\n",
    "    if prepare_df['Power(kW)'].dtype.name == 'object':\n",
    "        prepare_df['Power(kW)'] = prepare_df['Power(kW)'].apply(lambda item:str(item).replace(',',''))\n",
    "        prepare_df['Power(kW)'] = prepare_df['Power(kW)'].astype(float)\n",
    "    return prepare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e50480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    unload_status = 0\n",
    "    load_status = 1\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize a Dataset object.\n",
    "\n",
    "        Attributes:\n",
    "            status (int): The status of the dataset (unload_status or load_status).\n",
    "            dataframe (pd.DataFrame): The main dataset DataFrame.\n",
    "            antenna_dataframe (pd.DataFrame): Antenna data subset.\n",
    "            param_dataframe (pd.DataFrame): Param data subset.\n",
    "            Antenna_columns (None or List[str]): List of columns in the Antenna DataFrame.\n",
    "            Param_columns (None or List[str]): List of columns in the Param DataFrame.\n",
    "            remove_key (str): Key for removing rows from the Antenna DataFrame.\n",
    "            remove_values (List[str]): Values to remove from the Antenna DataFrame.\n",
    "            target_EID (List[str]): List of target EIDs.\n",
    "            Site_Height_bigger_than (int): Threshold for site height.\n",
    "            Date_onwards (str): Start date for filtering data.\n",
    "            statistics (Dict[str, Dict[str, float]]): Dictionary to store calculated statistics.\n",
    "            name (None or str): Dataset name.\n",
    "        \"\"\"\n",
    "        self.status = Dataset.unload_status\n",
    "        self.dataframe = None\n",
    "        self.antenna_dataframe = None\n",
    "        self.param_dataframe = None\n",
    "        self.Antenna_colunms = None\n",
    "        self.Param_colunms = None\n",
    "        self.remove_key ='NGR'\n",
    "        self.remove_values = ['NZ02553847', 'SE213515', 'NT05399374', 'NT252675908']\n",
    "        self.target_EID = ['C18A', 'C18F', 'C188']\n",
    "        self.Site_Height_bigger_than = 75\n",
    "        self.Date_onwards = '2001'\n",
    "        self.statistics = {}\n",
    "        self.name = None\n",
    "    \n",
    "    def statistic_in_use_erp_total(self):\n",
    "        \"\"\"\n",
    "        Calculate statistics for In-Use ERP Total.\n",
    "\n",
    "        This method calculates mean, mode, and median statistics for the 'In-Use ERP Total' column\n",
    "        based on specified conditions and stores the results in the 'statistics' attribute.\n",
    "        \"\"\"\n",
    "        statistic = {}\n",
    "        temp_df = self.dataframe.copy()[['Date','Site Height','Power(kW)']]\n",
    "        temp_df['Site Height'] = temp_df['Site Height'].astype(float)\n",
    "        temp_df['Power(kW)'] = temp_df['Power(kW)'].astype(float)\n",
    "        temp_df = processing_nan_funcs['mode'](temp_df)\n",
    "        temp_df = temp_df[pd.to_datetime(temp_df['Date']) >= pd.to_datetime(self.Date_onwards)]\n",
    "        temp_df = temp_df[temp_df['Site Height'].astype(float) > 75]\n",
    "        statistic['mean'] = temp_df['Power(kW)'].mean()\n",
    "        statistic['mode'] = temp_df['Power(kW)'].mode()[0]\n",
    "        statistic['median'] = temp_df['Power(kW)'].median()\n",
    "        self.statistics['In-Use ERP Total'] = statistic\n",
    "    \n",
    "    def visual_feature(self):\n",
    "        \"\"\"\n",
    "        Generate pie charts visualizing categorical feature distributions.\n",
    "\n",
    "        This method generates pie charts for specified categorical features in the dataset.\n",
    "        The pie charts display the distribution of each category within the feature.\n",
    "\n",
    "        Returns:\n",
    "            matplotlib.figure.Figure: The generated figure containing pie charts.\n",
    "        \"\"\"\n",
    "        if self.status != Dataset.load_status:\n",
    "            raise Exception('Dataset must be loaded before attempting any visual operations!')\n",
    "        plt.clf()\n",
    "        keys = ['Site', 'Freq.', 'Block', 'Serv Label1', 'Serv Label2', 'Serv Label3', 'Serv Label4','Serv Label10']\n",
    "        fig = plt.figure(figsize=(20,5),dpi=100)\n",
    "        fig.subplots_adjust(wspace=0,hspace=0.3)\n",
    "        i = 1\n",
    "        for item in keys:\n",
    "            ax1 = fig.add_subplot(2,4,i)\n",
    "            ax1.set_title(item,fontdict={'size':7})\n",
    "            temp_df = processing_nan_funcs['mode'](pd.DataFrame(self.dataframe[item].copy()))\n",
    "            colors = cm.get_cmap('Wistia')(np.arange(len(temp_df[item].value_counts().index))/len(temp_df[item].value_counts().index))\n",
    "            patches,l_text,p_text =ax1.pie(temp_df[item].value_counts().values,labels=temp_df[item].value_counts().index,\n",
    "                                           autopct=make_autopct(temp_df[item].value_counts().values),colors=colors)\n",
    "            for t in l_text:\n",
    "                t.set_size(6)\n",
    "            for t in p_text:\n",
    "                t.set_size(7)\n",
    "            i+=1\n",
    "        return fig\n",
    " \n",
    "\n",
    "    #This method generates count plots to visualize correlations between pairs of categorical features\n",
    "    #in the dataset. Each count plot displays the distribution of categories within pairs of features.\n",
    "\n",
    "          \n",
    "    def visual_feature_cor(self):\n",
    "        \n",
    "        if self.status != Dataset.load_status:\n",
    "            raise Exception('Dataset must be loaded before attempting any visual operations!')\n",
    "        plt.clf()\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "        fig.subplots_adjust(wspace=0.6,hspace=0.3)\n",
    "        plt.subplot(2,3,1)\n",
    "        sns.countplot(processing_nan_funcs['mode'](self.dataframe[[ 'Freq.', 'Block']].copy()),y='Freq.',hue='Block')\n",
    "        plt.subplot(2,3,2)\n",
    "        sns.countplot(processing_nan_funcs['mode'](self.dataframe[[ 'Block', 'Serv Label1']].copy()),y='Block',hue='Serv Label1')\n",
    "        plt.subplot(2,3,3)\n",
    "        sns.countplot(processing_nan_funcs['mode'](self.dataframe[[ 'Serv Label1', 'Serv Label2']].copy()),y='Serv Label1',hue='Serv Label2')\n",
    "        plt.subplot(2,3,4)\n",
    "        sns.countplot(processing_nan_funcs['mode'](self.dataframe[[ 'Serv Label2', 'Serv Label3']].copy()),y='Serv Label2',hue='Serv Label3')\n",
    "        plt.subplot(2,3,6)\n",
    "        sns.countplot(processing_nan_funcs['mode'](self.dataframe[[ 'Serv Label3', 'Serv Label4']].copy()),y='Serv Label3',hue='Serv Label4')\n",
    "        return fig\n",
    "    \n",
    "    @property\n",
    "    def key_types(self):\n",
    "        \"\"\"\n",
    "        Return a dictionary specifying attribute names and their corresponding data types.\n",
    "\n",
    "        Returns:\n",
    "            dict: Attribute names and their corresponding data types.\n",
    "        \"\"\"\n",
    "        return {'status':int,'dataframe':dict,'remove_key':str,'remove_values':list,'statistics':dict,\n",
    "                'target_EID':list,'Antenna_colunms':list,'Param_colunms':list,'name':str,\n",
    "                'Site_Height_bigger_than':int, 'Date_onwards':str,'antnna_dataframe':dict,\n",
    "                'param_dataframe':dict}\n",
    "        \n",
    "    \n",
    "    def load(self, from_:Literal['origin','prepared'], path:str):\n",
    "        \"\"\"\n",
    "        Load data from specified sources and prepare the dataset.\n",
    "\n",
    "        Args:\n",
    "            from_ (Literal['origin', 'prepared']): Source of the data (origin or prepared).\n",
    "            path (str): Path to the dataset file.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the prepared dataset is not in JSON format.\n",
    "        \"\"\"\n",
    "        self._set_default() # setting default before load other dataset\n",
    "        \n",
    "        if from_ == 'origin':\n",
    "            dfs_dict = load_dataset(path)\n",
    "            self.Antenna_colunms = list(dfs_dict['Antenna'].columns)\n",
    "            self.Param_colunms = list(dfs_dict['Param'].columns)\n",
    "            self.antnna_dataframe = dfs_dict['Antenna']\n",
    "            self.param_dataframe = dfs_dict['Param']\n",
    "            self.proprecessing()\n",
    "            self.name = Path(path).stem\n",
    "            self.status = Dataset.load_status\n",
    "            \n",
    "        elif from_ == 'prepared':\n",
    "            if path.split('.')[-1] != 'json':\n",
    "                raise ValueError('The prepared dataset must be in JSON')\n",
    "            with open(path,'r') as f:\n",
    "                temp_dataset = json.load(f)\n",
    "                self._load_checker(temp_dataset)\n",
    "                for k,t in self.key_types.items():\n",
    "                    if 'dataframe' not in k:\n",
    "                        self.__setattr__(k,temp_dataset[k])\n",
    "                    else:\n",
    "                        self.__setattr__(k,transform_json2df(temp_dataset[k]))\n",
    "            self.status = Dataset.load_status\n",
    "    \n",
    "    def back_up(self,name=None):\n",
    "        \"\"\"\n",
    "        Create a backup of the dataset in JSON format.\n",
    "\n",
    "        Args:\n",
    "            name (str, optional): Name of the backup file. If None, a default name is used.\n",
    "\n",
    "        Notes:\n",
    "            The backup is created in the 'back_up' directory.\n",
    "        \"\"\"\n",
    "        if self.status != Dataset.load_status:\n",
    "            return\n",
    "        if not os.path.exists('./back_up'):\n",
    "            os.makedirs('./back_up')\n",
    "        back_up_json = {}\n",
    "        for k,t in self.key_types.items():\n",
    "            if 'dataframe' not in k:\n",
    "                back_up_json[k] = self.__getattribute__(k)\n",
    "            else:\n",
    "                back_up_json[k] =  transform_df2json(self.__getattribute__(k))\n",
    "        if name is None:\n",
    "            with open(f'./back_up/bk.json','w') as f:\n",
    "                json.dump(back_up_json,f)\n",
    "        else:\n",
    "            with open(f'./{name}.json','w') as f:\n",
    "                json.dump(back_up_json,f)\n",
    "    \n",
    "    def _load_checker(self,temp_dataset):\n",
    "        \"\"\"\n",
    "        Check the validity of the loaded JSON dataset.\n",
    "\n",
    "        Args:\n",
    "            temp_dataset (dict): Loaded JSON dataset.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the format of the JSON dataset is not suitable for the program.\n",
    "        \"\"\"\n",
    "        for k,t in self.key_types.items():\n",
    "            if k in temp_dataset and isinstance(temp_dataset[k],t) or temp_dataset[k] == None:\n",
    "                continue\n",
    "            else:\n",
    "                print(k,type(temp_dataset[k]),t)\n",
    "                raise ValueError('Format of JSON file is not suitable for this program!')\n",
    "            \n",
    "    def proprecessing(self):\n",
    "        \"\"\"\n",
    "        Perform data preprocessing on the loaded dataframes and create the main dataset.\n",
    "        \"\"\"\n",
    "        dis_dict = {'Antenna':remove_data(self.antnna_dataframe),'Param':self.param_dataframe}\n",
    "        self.dataframe = extract_infomation(dis_dict)\n",
    "    \n",
    "    def setattr(self, __name: str, __value: Any) -> None:\n",
    "        \"\"\"\n",
    "        Set the attribute values of the dataset dynamically.\n",
    "\n",
    "        Args:\n",
    "            __name (str): Name of the attribute to be set.\n",
    "            __value (Any): Value to be set for the attribute.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If the dataset is not loaded before attempting to set attributes.\n",
    "        \"\"\"\n",
    "        if self.status != Dataset.load_status:\n",
    "            raise Exception('Dataset must be loaded before setting attributes!')\n",
    "        if __name == 'remove_key':\n",
    "            if __value in self.Antenna_colunms:\n",
    "                self.remove_key = __value\n",
    "            else:\n",
    "                raise Exception('Invalid Remove Key!')\n",
    "        elif __name == 'remove_values':\n",
    "            self.remove_values = [item.strip() for item in __value.split(';')]\n",
    "        elif __name == 'target_EID':\n",
    "            self.target_EID = [item.strip() for item in __value.split(';')]\n",
    "        elif __name == 'Site_Height_bigger_than':\n",
    "            self.Site_Height_bigger_than = int(__value)\n",
    "        elif __name == 'Date_onwards':\n",
    "            validate(__value)\n",
    "            self.Date_onwards = __value\n",
    "            \n",
    "    def _set_default(self):\n",
    "        \"\"\"\n",
    "        Set default values for the dataset attributes.\n",
    "        \"\"\"\n",
    "        self.status = Dataset.unload_status\n",
    "        self.dataframe = None\n",
    "        self.Antenna_colunms = None\n",
    "        self.Param_colunms = None\n",
    "        self.remove_key ='NGR'\n",
    "        self.remove_values = ['NZ02553847', 'SE213515', 'NT05399374', 'NT252675908']\n",
    "        self.target_EID = ['C18A', 'C18F', 'C188']\n",
    "        self.Site_Height_bigger_than = 75\n",
    "        self.Date_onwards = '2001'\n",
    "        self.statistics = {}\n",
    "        self.name = None\n",
    "\n",
    "\n",
    "\n",
    "class GUI_application:\n",
    "    \"\"\"\n",
    "        Initialize the GUI application and its components.\n",
    "        \"\"\"\n",
    "    def __init__(self):\n",
    "        self.dataset = Dataset()\n",
    "        self.window = tkinter.Tk()\n",
    "        self.set_ui()\n",
    "        self.window.resizable(width=False, height=False)\n",
    "        self.window.protocol(\"WM_DELETE_WINDOW\",self.close) # back up\n",
    "    \n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Handle the close event of the window, including creating a backup if needed.\n",
    "        \"\"\"\n",
    "        if messagebox.askokcancel(\"Quit\", \"Do you want to back up?\"):\n",
    "            if self.dataset.status == Dataset.load_status:\n",
    "                self.dataset.back_up()\n",
    "        self.window.destroy()\n",
    "        import sys\n",
    "        sys.exit(0)\n",
    "        \n",
    "    def set_ui(self):\n",
    "        \"\"\"\n",
    "        Set up the user interface components of the GUI.\n",
    "        \"\"\"\n",
    "        #setting title\n",
    "        self.window.title(\"Data Processing\")\n",
    "        #setting window size\n",
    "        width=1300\n",
    "        height=500\n",
    "        screenwidth = self.window.winfo_screenwidth()\n",
    "        screenheight = self.window.winfo_screenheight()\n",
    "        alignstr = '%dx%d+%d+%d' % (width, height, (screenwidth - width) / 2, (screenheight - height) / 2)\n",
    "        self.window.geometry(alignstr)\n",
    "        self.window.resizable(width=False, height=False)\n",
    "\n",
    "        # Dataset Name Label\n",
    "        self.dataset_name_textvar = tk.StringVar(value=\"Dataset Name: \")\n",
    "        self.dataset_name_label = tk.Label(self.window,textvariable=self.dataset_name_textvar)\n",
    "        ft = tkFont.Font(family='Times',size=14)\n",
    "        self.dataset_name_label[\"font\"] = ft\n",
    "        self.dataset_name_label[\"fg\"] = \"#333333\"\n",
    "        self.dataset_name_label[\"justify\"] = \"center\"\n",
    "        self.dataset_name_label.place(x=1030,y=70,width=252,height=37)\n",
    "\n",
    "        # Load Initial Dataset Button\n",
    "        self.load_init_data_button=tk.Button(self.window)\n",
    "        self.load_init_data_button[\"bg\"] = \"#f0f0f0\"\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.load_init_data_button[\"font\"] = ft\n",
    "        self.load_init_data_button[\"fg\"] = \"#000000\"\n",
    "        self.load_init_data_button[\"justify\"] = \"center\"\n",
    "        self.load_init_data_button[\"text\"] = \"Load Initial\"\n",
    "        self.load_init_data_button.place(x=950,y=10,width=100,height=30)\n",
    "        self.load_init_data_button[\"command\"] = self.load_init_dataset\n",
    "\n",
    "        # Load Prepared Dataset Button\n",
    "        self.load_prepare_data_button=tk.Button(self.window)\n",
    "        self.load_prepare_data_button[\"bg\"] = \"#f0f0f0\"\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.load_prepare_data_button[\"font\"] = ft\n",
    "        self.load_prepare_data_button[\"fg\"] = \"#000000\"\n",
    "        self.load_prepare_data_button[\"justify\"] = \"center\"\n",
    "        self.load_prepare_data_button[\"text\"] = \"Load Prepared\"\n",
    "        self.load_prepare_data_button.place(x=1060,y=10,width=100,height=30)\n",
    "        self.load_prepare_data_button[\"command\"] = self.load_prepare_dataset\n",
    "\n",
    "        # Save Dataset Button\n",
    "        self.save_data_button=tk.Button(self.window)\n",
    "        self.save_data_button[\"bg\"] = \"#f0f0f0\"\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.save_data_button[\"font\"] = ft\n",
    "        self.save_data_button[\"fg\"] = \"#000000\"\n",
    "        self.save_data_button[\"justify\"] = \"center\"\n",
    "        self.save_data_button[\"text\"] = \"Save Dataset\"\n",
    "        self.save_data_button.place(x=1170,y=10,width=100,height=30)\n",
    "        self.save_data_button[\"command\"] = self.save_dataset\n",
    "\n",
    "        #Remove key label\n",
    "        GLabel_844=tk.Label(self.window)\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        GLabel_844[\"font\"] = ft\n",
    "        GLabel_844[\"fg\"] = \"#333333\"\n",
    "        GLabel_844[\"justify\"] = \"center\"\n",
    "        GLabel_844[\"text\"] = \"Remove Key:\"\n",
    "        GLabel_844.place(x=1030,y=100,width=260,height=44)\n",
    "\n",
    "        #Remove key entry field\n",
    "        self.remove_key = tk.StringVar(value=\"NGR\")\n",
    "        self.remove_key_entry=tk.Entry(self.window,textvariable=self.remove_key)\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.remove_key_entry[\"font\"] = ft\n",
    "        self.remove_key_entry[\"fg\"] = \"#333333\"\n",
    "        self.remove_key_entry[\"justify\"] = \"center\"\n",
    "        self.remove_key_entry.place(x=1030,y=130,width=250,height=30)\n",
    "\n",
    "        #Remove values label\n",
    "        GLabel_499=tk.Label(self.window)\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        GLabel_499[\"font\"] = ft\n",
    "        GLabel_499[\"fg\"] = \"#333333\"\n",
    "        GLabel_499[\"justify\"] = \"center\"\n",
    "        GLabel_499[\"text\"] = \"Remove Values:\"\n",
    "        GLabel_499.place(x=1030,y=160,width=260,height=44)\n",
    "\n",
    "        #Remove values entry field\n",
    "        self.remove_values = tk.StringVar(value=\"NZ02553847; SE213515;NT05399374;NT252675908\")\n",
    "        self.remove_values_entry=tk.Entry(self.window,textvariable=self.remove_values)\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.remove_values_entry[\"font\"] = ft\n",
    "        self.remove_values_entry[\"fg\"] = \"#333333\"\n",
    "        self.remove_values_entry[\"justify\"] = \"center\"\n",
    "        self.remove_values_entry.place(x=1030,y=190,width=250,height=30)\n",
    "\n",
    "        # Canvas for displaying plots\n",
    "        self.canvas=tk.Canvas(self.window)\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.canvas.place(x=0,y=10,width=936,height=484)\n",
    "\n",
    "        #Select EID label\n",
    "        GLabel_442=tk.Label(self.window)\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        GLabel_442[\"font\"] = ft\n",
    "        GLabel_442[\"fg\"] = \"#333333\"\n",
    "        GLabel_442[\"justify\"] = \"center\"\n",
    "        GLabel_442[\"text\"] = \"Select EID:\"\n",
    "        GLabel_442.place(x=1030,y=220,width=260,height=44)\n",
    "\n",
    "        #Select EID entry field\n",
    "        self.eid = tk.StringVar(value=\"C18A;C18F;C188\")\n",
    "        self.eid_entry=tk.Entry(self.window,textvariable=self.eid)\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.eid_entry[\"font\"] = ft\n",
    "        self.eid_entry[\"fg\"] = \"#333333\"\n",
    "        self.eid_entry[\"justify\"] = \"center\"\n",
    "        self.eid_entry.place(x=1030,y=250,width=250,height=30)\n",
    "\n",
    "        #Site Height label\n",
    "        GLabel_117=tk.Label(self.window)\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        GLabel_117[\"font\"] = ft\n",
    "        GLabel_117[\"fg\"] = \"#333333\"\n",
    "        GLabel_117[\"justify\"] = \"center\"\n",
    "        GLabel_117[\"text\"] = \"Site Height >:\"\n",
    "        GLabel_117.place(x=1030,y=280,width=260,height=44)\n",
    "        \n",
    "        #Site Height entry field\n",
    "        self.bt = tk.StringVar(value=\"75\")\n",
    "        self.bt_entry=tk.Entry(self.window,textvariable=self.bt)\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.bt_entry[\"font\"] = ft\n",
    "        self.bt_entry[\"fg\"] = \"#333333\"\n",
    "        self.bt_entry[\"justify\"] = \"center\"\n",
    "        self.bt_entry.place(x=1030,y=310,width=250,height=30)\n",
    "\n",
    "        #From Date label\n",
    "        GLabel_56=tk.Label(self.window)\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        GLabel_56[\"font\"] = ft\n",
    "        GLabel_56[\"fg\"] = \"#333333\"\n",
    "        GLabel_56[\"justify\"] = \"center\"\n",
    "        GLabel_56[\"text\"] = \"From Date:\"\n",
    "        GLabel_56.place(x=1030,y=340,width=260,height=44)\n",
    "\n",
    "        #From Date entry field\n",
    "        self.date = tk.StringVar(value=\"2001_01_01\")\n",
    "        self.date_entry=tk.Entry(self.window,textvariable=self.date)\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.date_entry[\"font\"] = ft\n",
    "        self.date_entry[\"fg\"] = \"#333333\"\n",
    "        self.date_entry[\"justify\"] = \"center\"\n",
    "        self.date_entry.place(x=1030,y=370,width=250,height=30)\n",
    "        \n",
    "        # Apply Filters Button\n",
    "        self.apply_button=tk.Button(self.window)\n",
    "        self.apply_button[\"bg\"] = \"#f0f0f0\"\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.apply_button[\"font\"] = ft\n",
    "        self.apply_button[\"fg\"] = \"#000000\"\n",
    "        self.apply_button[\"justify\"] = \"center\"\n",
    "        self.apply_button[\"text\"] = \"Apply\\nFilters\"\n",
    "        self.apply_button.place(x=950,y=130,width=70,height=35)\n",
    "        self.apply_button[\"command\"] = self.apply\n",
    "        \n",
    "        # Show Features Button\n",
    "        self.show_feature_button=tk.Button(self.window)\n",
    "        self.show_feature_button[\"bg\"] = \"#f0f0f0\"\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.show_feature_button[\"font\"] = ft\n",
    "        self.show_feature_button[\"fg\"] = \"#000000\"\n",
    "        self.show_feature_button[\"justify\"] = \"center\"\n",
    "        self.show_feature_button[\"text\"] = \"Show\\nFeatures\"\n",
    "        self.show_feature_button.place(x=950,y=170,width=70,height=35)\n",
    "        self.show_feature_button[\"command\"] = self.show_feature \n",
    "\n",
    "        # Show Feature Correlation Button\n",
    "        self.show_feature_cor_button=tk.Button(self.window)\n",
    "        self.show_feature_cor_button[\"bg\"] = \"#f0f0f0\"\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.show_feature_cor_button[\"font\"] = ft\n",
    "        self.show_feature_cor_button[\"fg\"] = \"#000000\"\n",
    "        self.show_feature_cor_button[\"justify\"] = \"center\"\n",
    "        self.show_feature_cor_button[\"text\"] = \"Show\\nFeature\\nCorrelation\"\n",
    "        self.show_feature_cor_button.place(x=950,y=210,width=70,height=55)\n",
    "        self.show_feature_cor_button[\"command\"] = self.show_feature_cor\n",
    "        \n",
    "         # Show Statistics Button\n",
    "        self.show_statistics_button=tk.Button(self.window)\n",
    "        self.show_statistics_button[\"bg\"] = \"#f0f0f0\"\n",
    "        ft = tkFont.Font(family='Times',size=10)\n",
    "        self.show_statistics_button[\"font\"] = ft\n",
    "        self.show_statistics_button[\"fg\"] = \"#000000\"\n",
    "        self.show_statistics_button[\"justify\"] = \"center\"\n",
    "        self.show_statistics_button[\"text\"] = \"Show\\nStatistics\"\n",
    "        self.show_statistics_button.place(x=950,y=270,width=70,height=35)\n",
    "        self.show_statistics_button[\"command\"] = self.show_statictis\n",
    "\n",
    " # Run the main GUI loop, handling exceptions and potential backup.   \n",
    "    def run(self):\n",
    "        \n",
    "        try:\n",
    "            self.window.mainloop()\n",
    "        except:\n",
    "            if self.dataset.status == Dataset.load_status:\n",
    "                self.dataset.back_up()\n",
    "        \n",
    "    def load_init_dataset(self):\n",
    "        \"\"\"\n",
    "        Load the initial dataset from a directory and update UI elements accordingly.\n",
    "        \"\"\"\n",
    "        from tkinter import filedialog\n",
    "        path_ = filedialog.askdirectory()\n",
    "        if path_ is None or not os.path.exists(path_):\n",
    "            messagebox.askokcancel(\"Warning\",\"Path does not exist!\")\n",
    "        else:\n",
    "            try:\n",
    "                self.dataset.load('origin',path_)\n",
    "                self.dataset_name_textvar.set(f\"dataset name:{self.dataset.name}\")\n",
    "            except Exception as e:\n",
    "                messagebox.askokcancel(\"Warning\",str(e))\n",
    "    \n",
    "    def load_prepare_dataset(self):\n",
    "        from tkinter import filedialog\n",
    "        path_ = filedialog.askopenfilename()\n",
    "        if path_ is None or not os.path.exists(path_):\n",
    "            messagebox.askokcancel(\"Warning\",\"Path does not exist!\")\n",
    "        else:\n",
    "            try:\n",
    "                self.dataset.load('prepared',path_)\n",
    "                self.dataset_name_textvar.set(f\"dataset name:{self.dataset.name}\")\n",
    "                self.bt.set(str(self.dataset.Site_Height_bigger_than))\n",
    "                self.date.set(self.dataset.Date_onwards)\n",
    "                self.remove_key.set(self.dataset.remove_key)\n",
    "                self.remove_values.set(';'.join(self.dataset.remove_values))\n",
    "                self.eid.set(';'.join(self.dataset.target_EID))\n",
    "            except Exception as e:\n",
    "                messagebox.askokcancel(\"Warning\",str(e))      \n",
    "                \n",
    "    def save_dataset(self):\n",
    "        \"\"\"\n",
    "        Save the dataset, creating a backup if possible, and handling exceptions.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.dataset.back_up(self.dataset.name)\n",
    "        except Exception as e:\n",
    "            messagebox.askokcancel(\"Warning\",str(e))\n",
    "                \n",
    "    def apply(self):\n",
    "        \"\"\"\n",
    "        Apply the selected filters to the dataset and handle exceptions.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            remove_key = self.remove_key.get()\n",
    "            self.dataset.setattr('remove_key',remove_key)\n",
    "            remove_values =self.remove_values.get()\n",
    "            self.dataset.setattr('remove_values',remove_values)\n",
    "            eid = self.eid.get()\n",
    "            self.dataset.setattr('target_EID',eid)\n",
    "            bt = self.bt.get()\n",
    "            self.dataset.setattr('Site_Height_bigger_than',bt)\n",
    "            date = self.date.get()\n",
    "            self.dataset.setattr('Date_onwards',date)\n",
    "            self.dataset.proprecessing()\n",
    "        except Exception as e:\n",
    "            messagebox.askokcancel(\"Warning\",str(e))\n",
    "    \n",
    "    def show_feature(self):\n",
    "        \"\"\"\n",
    "        Display the visual features of the dataset using matplotlib and update canvas.\n",
    "        \"\"\"\n",
    "        from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "        try:\n",
    "            if self.dataset.status == Dataset.unload_status:\n",
    "                raise Exception(\"Warning\",\"The dataset is unloaded!\")\n",
    "            fig = self.dataset.visual_feature()\n",
    "            canvas_spice = FigureCanvasTkAgg(fig,self.window)\n",
    "            canvas_spice.get_tk_widget().place(x=0,y=10,width=936,height=484)\n",
    "            canvas_spice.draw()\n",
    "        except Exception as e:\n",
    "            messagebox.askokcancel(\"Warning\",str(e))\n",
    "    \n",
    "    def show_feature_cor(self):\n",
    "        \"\"\"\n",
    "        Display the visual feature correlations of the dataset using matplotlib and update canvas.\n",
    "        \"\"\"\n",
    "        from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "        try:\n",
    "            if self.dataset.status == Dataset.unload_status:\n",
    "                raise Exception(\"Warning\",\"The dataset is unloaded!\")\n",
    "            fig = self.dataset.visual_feature_cor()\n",
    "            canvas_spice = FigureCanvasTkAgg(fig,self.window)\n",
    "            canvas_spice.get_tk_widget().place(x=0,y=10,width=936,height=484)\n",
    "            canvas_spice.draw()\n",
    "        except Exception as e:\n",
    "            messagebox.askokcancel(\"Warning\",str(e))\n",
    "    \n",
    "    def show_statictis(self):\n",
    "        \"\"\"\n",
    "        Display the statistics of the dataset and update the UI element.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.dataset.status == Dataset.unload_status:\n",
    "                raise Exception(\"Warning\",\"The dataset is unloaded!\")\n",
    "            self.dataset.statistic_in_use_erp_total()\n",
    "            tmp = tk.StringVar(value='In-Use ERP Total:\\n'+'\\n'.join([f'{k} = {v}' for k,v in self.dataset.statistics['In-Use ERP Total'].items()]))\n",
    "            label = tk.Label(self.window,textvariable=tmp)\n",
    "            ft = tkFont.Font(family='Times',size=10)\n",
    "            label[\"font\"] = ft\n",
    "            label[\"fg\"] = \"#333333\"\n",
    "            label[\"justify\"] = \"center\"\n",
    "            label[\"text\"] = \"Date_onwards\"\n",
    "            label.place(x=0,y=10,width=936,height=484)\n",
    "        except Exception as e:\n",
    "            messagebox.askokcancel(\"Warning\",str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aec2ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the GUI application\n",
    "application = GUI_application()\n",
    "# Run the GUI application's main loop\n",
    "application.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c67299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa56fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "æ— ",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
